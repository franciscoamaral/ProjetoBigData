{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\user\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.5)\n",
      "Requirement already satisfied: findspark in c:\\users\\user\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introdução"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivos do Projeto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto de BigData tem como objetivo usar algoritmos de Machine Learning, recorrendo ao uso do PySpark, pois o mesmo ajuda o processamento de grandes quantidades de dados e é incorpurado com ferramentas para prever resultados importantes em relação a um conjunto de dados.\n",
    "O Spark é uma ferramenta poderosa que permite o processamento distribuído de dados.\n",
    "Iremos usar o Spark para ler, limpar e preparar os dados, avaliar e ajustar modelos e, finalmente, fazer previsões precisas e relevantes.\n",
    "Este projeto é uma excelente oportunidade para aplicar e praticar habilidades de Machine Learning em um ambiente de grande escala e de alta performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introdução ao Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso dataset inclui dados de percentagem de gordura, dados de pressão sanguínea dialóstica e sistólica, alguns exercícios tais como broad jump, abdominais e amplitude no sit and bend;\n",
    "Temos como objetivo utilizar técnicas Machine Learning para identificar padrões e tendências nos dados e talvez prever a queda de performance com idade;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar uma \"SparkSession\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-LQQALU0R:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Pyspark ProjetoBD</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x21cb6989788>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Pyspark ProjetoBD\")\\\n",
    "                    .config(\"spark.memory.offHeap.enabled\",\"true\")\\\n",
    "                    .config(\"spark.memory.offHeap.size\",\"20g\")\\\n",
    "                    .getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(r'C:\\Users\\user\\Desktop\\ESTB\\3 ano\\1º semestre\\Big Data\\Trabalho 2\\bodyPerformance.csv',header=True,sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização dos dados e Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Linhas: 13393\n",
      "Numero de Colunas: 12\n",
      "Esquema do DataFrame: \n",
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- height_cm: string (nullable = true)\n",
      " |-- weight_kg: string (nullable = true)\n",
      " |-- body fat_%: string (nullable = true)\n",
      " |-- diastolic: string (nullable = true)\n",
      " |-- systolic: string (nullable = true)\n",
      " |-- gripForce: string (nullable = true)\n",
      " |-- sit and bend forward_cm: string (nullable = true)\n",
      " |-- sit-ups counts: string (nullable = true)\n",
      " |-- broad jump_cm: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de Linhas:\", df.count())\n",
    "print(\"Numero de Colunas:\", len(df.columns))\n",
    "print(\"Esquema do DataFrame: \")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+---------+----------+---------+--------+---------+-----------------------+--------------+-------------+-----+\n",
      "| age|gender|height_cm|weight_kg|body fat_%|diastolic|systolic|gripForce|sit and bend forward_cm|sit-ups counts|broad jump_cm|class|\n",
      "+----+------+---------+---------+----------+---------+--------+---------+-----------------------+--------------+-------------+-----+\n",
      "|27.0|     M|    172.3|    75.24|      21.3|     80.0|   130.0|     54.9|                   18.4|          60.0|        217.0|    C|\n",
      "|25.0|     M|    165.0|     55.8|      15.7|     77.0|   126.0|     36.4|                   16.3|          53.0|        229.0|    A|\n",
      "|31.0|     M|    179.6|     78.0|      20.1|     92.0|   152.0|     44.8|                   12.0|          49.0|        181.0|    C|\n",
      "|32.0|     M|    174.5|     71.1|      18.4|     76.0|   147.0|     41.4|                   15.2|          53.0|        219.0|    B|\n",
      "|28.0|     M|    173.8|     67.7|      17.1|     70.0|   127.0|     43.5|                   27.1|          45.0|        217.0|    B|\n",
      "|36.0|     F|    165.4|     55.4|      22.0|     64.0|   119.0|     23.8|                   21.0|          27.0|        153.0|    B|\n",
      "|42.0|     F|    164.5|     63.7|      32.2|     72.0|   135.0|     22.7|                    0.8|          18.0|        146.0|    D|\n",
      "|33.0|     M|    174.9|     77.2|      36.9|     84.0|   137.0|     45.9|                   12.3|          42.0|        234.0|    B|\n",
      "|54.0|     M|    166.8|     67.5|      27.6|     85.0|   165.0|     40.4|                   18.6|          34.0|        148.0|    C|\n",
      "|28.0|     M|    185.0|     84.6|      14.4|     81.0|   156.0|     57.9|                   12.1|          55.0|        213.0|    B|\n",
      "+----+------+---------+---------+----------+---------+--------+---------+-----------------------+--------------+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das variáveis do Dataframe:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age: idade dos participantes deste estudo;\n",
    "gender: genero dos participantes;\n",
    "height_cm: altura dos participantes em centímetros;\n",
    "weight_kg: peso dos participantes em kilogramas;\n",
    "body fat_%: percentagem de gordura no corpo;\n",
    "diastolic: pressão sanguínea por minuto em relaxamento;\n",
    "systolic: prressão sanguínea por minuto em contração;\n",
    "gripForce: força aplicada pela mão para segurar ou levantar; \n",
    "sit and bend forward_cm: amplitude medida em centímetros deste exercício;\n",
    "sit-ups count: contagem de abdominais;\n",
    "broad jump_cm: distância em centímetros do salto sem impulso com os dois pés;\n",
    "class: classificação;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retirar a variável \"class\" que não será útil para a nossa análise\n",
    "df = df.drop(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13393, 11)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), len(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso dataset tem assim 13393 linhas e 11 colunas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual a idade mínima e máxima registada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(age)|\n",
      "+--------+\n",
      "|    64.0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"data\")\n",
    "spark.sql(\"SELECT MAX(`age`) FROM data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(age)|\n",
      "+--------+\n",
      "|    21.0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT MIN(`age`) FROM data\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar as características das nossas variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('height_cm', 'string'),\n",
       " ('weight_kg', 'string'),\n",
       " ('body fat_%', 'string'),\n",
       " ('diastolic', 'string'),\n",
       " ('systolic', 'string'),\n",
       " ('gripForce', 'string'),\n",
       " ('sit and bend forward_cm', 'string'),\n",
       " ('sit-ups counts', 'string'),\n",
       " ('broad jump_cm', 'string')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como as variáveis escontravam-se todas em tipo String, foi necessário mudar as variáveis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "df = df \\\n",
    "    .withColumn(\"age\", df[\"age\"].cast(IntegerType())) \\\n",
    "    .withColumn(\"gender\", df[\"gender\"].cast(StringType())) \\\n",
    "    .withColumn(\"height_cm\", df[\"height_cm\"].cast(DoubleType())) \\\n",
    "    .withColumn(\"weight_kg\", df[\"weight_kg\"].cast(DoubleType())) \\\n",
    "    .withColumn(\"body fat_%\", df[\"body fat_%\"].cast(DoubleType())) \\\n",
    "    .withColumn(\"diastolic\", df[\"diastolic\"].cast(IntegerType())) \\\n",
    "    .withColumn(\"systolic\", df[\"systolic\"].cast(IntegerType())) \\\n",
    "    .withColumn(\"gripForce\", df[\"gripForce\"].cast(DoubleType())) \\\n",
    "    .withColumn(\"sit and bend forward_cm\", df[\"sit and bend forward_cm\"].cast(DoubleType())) \\\n",
    "    .withColumn(\"sit-ups counts\", df[\"sit-ups counts\"].cast(IntegerType())) \\\n",
    "    .withColumn(\"broad jump_cm\", df[\"broad jump_cm\"].cast(IntegerType())) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('gender', 'string'),\n",
       " ('height_cm', 'double'),\n",
       " ('weight_kg', 'double'),\n",
       " ('body fat_%', 'double'),\n",
       " ('diastolic', 'int'),\n",
       " ('systolic', 'int'),\n",
       " ('gripForce', 'double'),\n",
       " ('sit and bend forward_cm', 'double'),\n",
       " ('sit-ups counts', 'int'),\n",
       " ('broad jump_cm', 'int')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------+-----------------+------------------+------------------+------------------+------------------+------------------+-----------------------+-----------------+------------------+\n",
      "|summary|              age|gender|        height_cm|         weight_kg|        body fat_%|         diastolic|          systolic|         gripForce|sit and bend forward_cm|   sit-ups counts|     broad jump_cm|\n",
      "+-------+-----------------+------+-----------------+------------------+------------------+------------------+------------------+------------------+-----------------------+-----------------+------------------+\n",
      "|  count|            13393| 13393|            13393|             13393|             13328|             13393|             13393|             13393|                  13393|            13393|             13393|\n",
      "|   mean|36.77510639886508|  null|168.5598073620558| 67.44731576196514|23.319833208283306| 78.79675950123199|130.23474949600538|36.963877398641166|      15.20926827447175|39.77114910774285|190.12961995072052|\n",
      "| stddev| 13.6256394752913|  null|8.426582550560232|11.949666342707413| 8.117568168027534|10.741959495336932|14.714349895943636|10.624864027335336|      8.456677009240225|14.27685267846424|39.867989846230564|\n",
      "|    min|               21|     F|            125.0|              26.3|               3.0|                 0|                 0|               0.0|                  -25.0|                0|                 0|\n",
      "|    max|               64|     M|            193.8|             138.1|           264.462|               156|               201|              70.5|                  213.0|               80|               303|\n",
      "+-------+-----------------+------+-----------------+------------------+------------------+------------------+------------------+------------------+-----------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumnRenamed('age','Age')\n",
    "df=df.withColumnRenamed('gender','Gender')\n",
    "df=df.withColumnRenamed('height_cm','Height')\n",
    "df=df.withColumnRenamed('weight_kg','Weight')\n",
    "df=df.withColumnRenamed('body fat_%','BodyFat')\n",
    "df=df.withColumnRenamed('diastolic','Dialostic')\n",
    "df=df.withColumnRenamed('systolic','Systolic')\n",
    "df=df.withColumnRenamed('gripForce','GripForce')\n",
    "df=df.withColumnRenamed('sit and bend forward_cm','SitBend')\n",
    "df=df.withColumnRenamed('sit-ups counts','SitUps')\n",
    "df=df.withColumnRenamed('broad jump_cm','BroadJump')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar se existem valores nulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age : Nenhum valor nulo\n",
      "Gender : Nenhum valor nulo\n",
      "Height : Nenhum valor nulo\n",
      "Weight : Nenhum valor nulo\n",
      "BodyFat : 65 missing values\n",
      "Dialostic : Nenhum valor nulo\n",
      "Systolic : Nenhum valor nulo\n",
      "GripForce : Nenhum valor nulo\n",
      "SitBend : Nenhum valor nulo\n",
      "SitUps : Nenhum valor nulo\n",
      "BroadJump : Nenhum valor nulo\n"
     ]
    }
   ],
   "source": [
    "missing_values = []\n",
    "for col in df.columns:\n",
    "    missing_values.append((col, df.filter(df[col].isNull()).count()))\n",
    "for col, val in missing_values:\n",
    "    if val == 0:\n",
    "        print(\"{} : Nenhum valor nulo\".format(col))\n",
    "    else:\n",
    "        print(\"{} : {} missing values\".format(col, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+-------+---------+--------+---------+-------+------+---------+\n",
      "|Age|Gender|Height|Weight|BodyFat|Dialostic|Systolic|GripForce|SitBend|SitUps|BroadJump|\n",
      "+---+------+------+------+-------+---------+--------+---------+-------+------+---------+\n",
      "| 27|     M| 172.3| 75.24|   21.3|       80|     130|     54.9|   18.4|    60|      217|\n",
      "| 25|     M| 165.0|  55.8|   15.7|       77|     126|     36.4|   16.3|    53|      229|\n",
      "| 31|     M| 179.6|  78.0|   20.1|       92|     152|     44.8|   12.0|    49|      181|\n",
      "| 32|     M| 174.5|  71.1|   18.4|       76|     147|     41.4|   15.2|    53|      219|\n",
      "| 28|     M| 173.8|  67.7|   17.1|       70|     127|     43.5|   27.1|    45|      217|\n",
      "| 36|     F| 165.4|  55.4|   22.0|       64|     119|     23.8|   21.0|    27|      153|\n",
      "| 42|     F| 164.5|  63.7|   32.2|       72|     135|     22.7|    0.8|    18|      146|\n",
      "| 33|     M| 174.9|  77.2|   36.9|       84|     137|     45.9|   12.3|    42|      234|\n",
      "| 54|     M| 166.8|  67.5|   27.6|       85|     165|     40.4|   18.6|    34|      148|\n",
      "| 28|     M| 185.0|  84.6|   14.4|       81|     156|     57.9|   12.1|    55|      213|\n",
      "| 42|     M| 169.2|  65.4|   19.3|       63|     110|     43.5|   16.0|    68|      211|\n",
      "| 57|     F| 153.0|  49.0|   20.9|       69|     106|     21.5|   30.0|     0|       90|\n",
      "| 27|     F| 156.0|  53.9|   35.5|       69|     116|     23.1|   13.1|    28|      144|\n",
      "| 22|     M| 175.7|  67.9|   11.3|       71|     103|     52.5|   19.2|    55|      232|\n",
      "| 24|     M| 181.0|  84.4|   20.4|       80|     120|     48.9|    7.2|    54|      213|\n",
      "| 45|     F| 159.0|  63.1|   30.9|       93|     144|     34.1|   19.0|    30|      155|\n",
      "| 25|     F| 164.2|  66.6|   30.2|       82|     120|     25.7|   22.9|    39|      178|\n",
      "| 26|     M| 179.9|  71.5|    9.7|       64|     135|     59.6|   17.8|    61|      239|\n",
      "| 26|     M| 169.2|  70.6|   21.0|       63|     129|     41.3|   15.1|    53|      225|\n",
      "| 21|     F| 162.7|  47.2|   18.9|       78|     133|     25.4|   20.5|    36|      137|\n",
      "+---+------+------+------+-------+---------+--------+---------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar missing values para podermos testar os nossos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age : Nenhum valor nulo\n",
      "Gender : Nenhum valor nulo\n",
      "Height : Nenhum valor nulo\n",
      "Weight : Nenhum valor nulo\n",
      "BodyFat : Nenhum valor nulo\n",
      "Dialostic : Nenhum valor nulo\n",
      "Systolic : Nenhum valor nulo\n",
      "GripForce : Nenhum valor nulo\n",
      "SitBend : Nenhum valor nulo\n",
      "SitUps : Nenhum valor nulo\n",
      "BroadJump : Nenhum valor nulo\n"
     ]
    }
   ],
   "source": [
    "missing_values = []\n",
    "for col in df.columns:\n",
    "    missing_values.append((col, df.filter(df[col].isNull()).count()))\n",
    "for col, val in missing_values:\n",
    "    if val == 0:\n",
    "        print(\"{} : Nenhum valor nulo\".format(col))\n",
    "    else:\n",
    "        print(\"{} : {} missing values\".format(col, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Height: double (nullable = false)\n",
      " |-- Weight: double (nullable = false)\n",
      " |-- BodyFat: double (nullable = false)\n",
      " |-- Dialostic: integer (nullable = true)\n",
      " |-- Systolic: integer (nullable = true)\n",
      " |-- GripForce: double (nullable = false)\n",
      " |-- SitBend: double (nullable = false)\n",
      " |-- SitUps: integer (nullable = true)\n",
      " |-- BroadJump: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, Age: int]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['Height','Weight','BodyFat','GripForce','SitBend','SitUps','BroadJump'], outputCol='features')\n",
    "assembler = assembler.transform(df)\n",
    "assembler.select('features','Age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|standard                                                                                                                           |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[20.4471977775314,6.2964101123975835,2.5791810459503974,5.167124949435115,2.1757955258188457,4.202606929642596,5.442963160093119]  |\n",
      "|[19.5808916615942,4.669586446993423,1.901086498658274,3.4259261959824805,1.9274710364590864,3.7123027878509602,5.743956514568315]  |\n",
      "|[21.313503893468596,6.527378904399409,2.433875071530657,4.216524548901514,1.418997082055769,3.4321289925414535,4.539983096667533]  |\n",
      "|[20.70827633301932,5.949956924394845,2.2280249411026904,3.8965204536723816,1.7973963039373073,3.7123027878509602,5.493128719172319]|\n",
      "|[20.625205883545892,5.665430151638975,2.070610135481305,4.0941700419021405,3.2045684103092786,3.1519551972319473,5.442963160093119]|\n",
      "|[19.628360489864733,4.636112709022145,2.6639428643619127,2.2400286666039295,2.483244893597596,1.8911731183391685,3.837665269558743]|\n",
      "|[19.521555626256035,5.330692771926184,3.899043646929709,2.136497929912151,0.0945998054703846,1.2607820788927788,3.662085812781546] |\n",
      "|[20.755745161289852,6.460431428456851,4.468158713407027,4.320055285593293,1.4544720091071632,2.9418248507498173,5.869370412266313] |\n",
      "|[19.794501388811593,5.648693282653335,3.342037411654036,3.802401602134401,2.1994454771864422,2.3814772601308047,3.712251371860745] |\n",
      "|[21.95433307512077,7.079695580925512,1.7436716930368883,5.449481504049055,1.430822057739567,3.852389685505713,5.342632041934721]   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scale = StandardScaler(inputCol='features', outputCol='standard')\n",
    "data_scale=scale.fit(assembler)\n",
    "data_scale_output=data_scale.transform(assembler)\n",
    "data_scale_output.select('standard').show(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+-------+---------+--------+---------+-------+------+---------+--------------------+\n",
      "|Age|Gender|Height|Weight|BodyFat|Dialostic|Systolic|GripForce|SitBend|SitUps|BroadJump|            features|\n",
      "+---+------+------+------+-------+---------+--------+---------+-------+------+---------+--------------------+\n",
      "| 27|     M| 172.3| 75.24|   21.3|       80|     130|     54.9|   18.4|    60|      217|[172.3,75.24,21.3...|\n",
      "| 25|     M| 165.0|  55.8|   15.7|       77|     126|     36.4|   16.3|    53|      229|[165.0,55.8,15.7,...|\n",
      "| 31|     M| 179.6|  78.0|   20.1|       92|     152|     44.8|   12.0|    49|      181|[179.6,78.0,20.1,...|\n",
      "| 32|     M| 174.5|  71.1|   18.4|       76|     147|     41.4|   15.2|    53|      219|[174.5,71.1,18.4,...|\n",
      "| 28|     M| 173.8|  67.7|   17.1|       70|     127|     43.5|   27.1|    45|      217|[173.8,67.7,17.1,...|\n",
      "| 36|     F| 165.4|  55.4|   22.0|       64|     119|     23.8|   21.0|    27|      153|[165.4,55.4,22.0,...|\n",
      "| 42|     F| 164.5|  63.7|   32.2|       72|     135|     22.7|    0.8|    18|      146|[164.5,63.7,32.2,...|\n",
      "| 33|     M| 174.9|  77.2|   36.9|       84|     137|     45.9|   12.3|    42|      234|[174.9,77.2,36.9,...|\n",
      "| 54|     M| 166.8|  67.5|   27.6|       85|     165|     40.4|   18.6|    34|      148|[166.8,67.5,27.6,...|\n",
      "| 28|     M| 185.0|  84.6|   14.4|       81|     156|     57.9|   12.1|    55|      213|[185.0,84.6,14.4,...|\n",
      "+---+------+------+------+-------+---------+--------+---------+-------+------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo_df= assembler.select(['features', 'Age'])\n",
    "modelo_df = modelo_df.withColumnRenamed(\"Age\", \"label\")\n",
    "modelo_df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "train, test = modelo_df.randomSplit([0.7, 0.3])\n",
    "#divisão do dataset em dois, 70% para treino e 30% para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr = LogisticRegression(featuresCol = 'features', labelCol = 'label').fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr_summary = Lr.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09433361629881154"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lr_summary.accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos analisar pela accuracy a regressão linear de 0,094, retiramos que o modelo não é fiável para prever se a idade afeta a performance nos exercícios do nosso data set, visto que pode existir indivíduos que tenham uma idade avançada e com boa performance e adolescentes com pouca aptidão fisica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.09088645418326693\n"
     ]
    }
   ],
   "source": [
    "e1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\") \n",
    "print(\"Accuracy = \",e1.evaluate(results)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naiveby = NaiveBayes(modelType=\"gaussian\")\n",
    "nb = Naiveby.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[140.5,49.6,32.1,...|   64|[-33.497763398171...|[2.51720189859315...|      35.0|\n",
      "|[141.0,46.1,25.5,...|   60|[-34.274401356927...|[9.21474238658230...|      35.0|\n",
      "|[144.7,43.1,28.3,...|   61|[-36.303054100024...|[2.27239099544285...|      41.0|\n",
      "|[144.9,50.8,33.9,...|   62|[-42.321973137002...|[7.71655120603505...|      43.0|\n",
      "|[145.5,47.4,29.4,...|   61|[-30.950194685838...|[3.37309023969197...|      41.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df = nb.transform(test)\n",
    "p_df.show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.003527336860670194\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "e2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\") \n",
    "print(\"Accuracy = \",e2.evaluate(p_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos concluir que o nosso dataset não é propício para fazer previsões acerca da idade na queda da performance física. No entanto, conseguimos entender e aplicar a aplicação PySpark e os seus algoritmos de classificação e análise e também consolidar a matéria dada em aula. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
